# multi_agent_system/agents/coordinator_agent.py
import asyncio
import json
from typing import Dict, List, Any, Optional, Callable
from .plugin_agent import PluginAgent
from ..models.agent_models import AgentType, AgentResponse
from ..core.iteration_controller import IterationController


class EnhancedCoordinatorAgent(PluginAgent):
    """å¢å¼ºçš„ä¸»åè°ƒ Agent - æ”¯æŒå¤šè½®è¿­ä»£"""

    def __init__(self, name: str = "æ™ºèƒ½åè°ƒå™¨", description: str = "æ”¯æŒå¤šè½®è¿­ä»£çš„åŠ¨æ€åè°ƒAgent"):
        super().__init__(AgentType.COORDINATOR, name, description)
        self.agent_registry: Dict[str, PluginAgent] = {}
        self.planning_strategies: Dict[str, Callable] = {}
        self.iteration_controller = IterationController(max_iterations=5)
        self.conversation_memory: List[Dict] = []

    def register_agent(self, agent: PluginAgent):
        """æ³¨å†Œ Agent"""
        self.agent_registry[agent.name] = agent
        print(f"âœ… æ³¨å†Œ Agent: {agent.name} ({agent.agent_type.value})")

    def unregister_agent(self, agent_name: str):
        """æ³¨é”€ Agent"""
        if agent_name in self.agent_registry:
            del self.agent_registry[agent_name]
            print(f"âŒ æ³¨é”€ Agent: {agent_name}")

    def register_planning_strategy(self, name: str, strategy_func: Callable):
        """æ³¨å†Œè§„åˆ’ç­–ç•¥"""
        self.planning_strategies[name] = strategy_func

    async def process_request(self, query: str, context: Dict[str, Any] = None) -> AgentResponse:
        """å¤„ç†è¯·æ±‚ - æ”¯æŒå¤šè½®è¿­ä»£"""
        # æ›´æ–°å¯¹è¯è®°å¿†
        self.conversation_memory.append({
            "role": "user",
            "content": query,
            "timestamp": asyncio.get_event_loop().time()
        })

        # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
        execution_context = {
            "last_query": query,
            "conversation_history": self.conversation_memory[-10:],  # æœ€è¿‘10è½®å¯¹è¯
            "available_agents": list(self.agent_registry.keys()),
            **(context or {})
        }

        print("ğŸš€ å¼€å§‹å¤šè½®è¿­ä»£æ‰§è¡Œ...")
        print(f"å¯ç”¨Agent: {execution_context['available_agents']}")

        # æ‰§è¡Œå¤šè½®è¿­ä»£
        iteration_result = await self.iteration_controller.execute_iteration_cycle(
            query, execution_context, self, execution_context['available_agents']
        )

        # ç”Ÿæˆæœ€ç»ˆå“åº”
        final_response = await self._generate_final_response(query, iteration_result)

        # æ›´æ–°å¯¹è¯è®°å¿†
        self.conversation_memory.append({
            "role": "assistant",
            "content": final_response,
            "timestamp": asyncio.get_event_loop().time(),
            "iteration_data": iteration_result
        })

        return AgentResponse(
            agent_type=self.agent_type,
            content=final_response,
            data={
                "query": query,
                "iteration_result": iteration_result,
                "agent_registry": list(self.agent_registry.keys()),
                "conversation_length": len(self.conversation_memory)
            },
            confidence=iteration_result.get("final_result", {}).get("confidence_score", 0.8),
            metadata={
                "iterations": iteration_result["iteration_count"],
                "strategy": "multi_iteration",
                "completion_reason": "normal" if iteration_result["iteration_count"] < 5 else "max_iterations"
            }
        )

    async def _generate_final_response(self, query: str, iteration_result: Dict) -> str:
        """ç”Ÿæˆæœ€ç»ˆå“åº”"""
        final_data = iteration_result["final_result"]
        agent_responses = final_data.get("agent_responses", {})

        if not agent_responses:
            return "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•è·å–è¶³å¤Ÿçš„ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"

        # æ„å»ºæ•´åˆæç¤º
        response_summaries = []
        for agent_name, response in agent_responses.items():
            response_summaries.append(f"## {agent_name}\n{response.content}")

        integration_prompt = f"""
ç”¨æˆ·åŸå§‹æŸ¥è¯¢: {query}

ç»è¿‡{iteration_result['iteration_count']}è½®è¿­ä»£æ”¶é›†ï¼Œè·å¾—ä»¥ä¸‹ä¸“ä¸šåˆ†æ:
{"".join(response_summaries)}

è¿­ä»£è¿‡ç¨‹æ‘˜è¦:
- æ€»è¿­ä»£è½®æ¬¡: {iteration_result['iteration_count']}
- æ”¶é›†åˆ°çš„å…³é”®ä¿¡æ¯: {len(agent_responses)}ä¸ªä¸“ä¸šåˆ†æ

è¯·åŸºäºä»¥ä¸Šæ‰€æœ‰ä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä¸ªå®Œæ•´ã€å‡†ç¡®ã€æœ‰ç”¨çš„æœ€ç»ˆå›ç­”ã€‚
ç¡®ä¿å›ç­”è‡ªç„¶æµç•…ï¼Œçªå‡ºå…³é”®ä¿¡æ¯ï¼Œå¹¶æä¾›å®ç”¨çš„å»ºè®®ã€‚
"""

        messages = [
            {"role": "system",
             "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•´åˆä¸“å®¶ï¼Œæ“…é•¿å°†å¤šè½®è¿­ä»£æ”¶é›†çš„ä¸“ä¸šä¿¡æ¯æ•´åˆæˆç”¨æˆ·å‹å¥½çš„æœ€ç»ˆå›ç­”ã€‚"},
            {"role": "user", "content": integration_prompt}
        ]

        return self._call_llm(messages)