# é¦–å…ˆå®‰è£…å¿…è¦çš„ä¾èµ–åŒ…ï¼š
# pip install langchain langchain-community langchain-mcp-adapters langchain-openai python-dotenv

import asyncio
import os

from langchain_classic.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.prompts import ChatPromptTemplate
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

load_dotenv()  # åŠ è½½ç¯å¢ƒå˜é‡ï¼Œä¾‹å¦‚ OPENAI_API_KEY


async def main():

    client = MultiServerMCPClient({
        "weather": {
            "url": "http://localhost:8000/sse",  # ä½ çš„SSE URL
            "transport": "sse",
        }
    })

    tools = await client.get_tools()
    print("âœ… ä»MCPæœåŠ¡å™¨è·å–åˆ°çš„å·¥å…·:")
    for tool in tools:
        print(f"   - {tool.name}: {tool.description}")

    # 4. è®¾ç½®LLMå’ŒAgent
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

    # Agentæç¤ºè¯æ¨¡æ¿ï¼ŒæŒ‡å¯¼å…¶å¦‚ä½•ä½¿ç”¨å·¥å…·
    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„åŠ©æ‰‹ï¼Œå¯ä»¥è°ƒç”¨å·¥å…·æ¥è·å–ä¿¡æ¯ã€‚è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚ä½¿ç”¨åˆé€‚çš„å·¥å…·ã€‚"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])

    # åˆ›å»ºèƒ½ç†è§£å·¥å…·è°ƒç”¨çš„Agent
    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)

    # 5. ä½¿ç”¨Agentæ‰§è¡Œä»»åŠ¡ï¼ˆç¤ºä¾‹ï¼šæŸ¥è¯¢å¤©æ°”ï¼‰
    print("\nğŸ¤– Agentå¼€å§‹å¤„ç†ç”¨æˆ·è¯·æ±‚...")
    try:
        result = await agent_executor.ainvoke({
            "input": "ä»Šå¤©åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"  # è¯·ç¡®ä¿MCPæœåŠ¡æä¾›å¤©æ°”æŸ¥è¯¢å·¥å…·
        })
        print(f"\nğŸ“ æœ€ç»ˆå›ç­”: {result['output']}")
    except Exception as e:
        print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")


# è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    asyncio.run(main())